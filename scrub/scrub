#!/usr/bin/env Rscript

suppressPackageStartupMessages(require(doParallel))
suppressPackageStartupMessages(require(dplyr))
suppressPackageStartupMessages(require(glue))
suppressPackageStartupMessages(require(magrittr))
suppressPackageStartupMessages(require(optparse))
suppressPackageStartupMessages(require(parallel))
suppressPackageStartupMessages(require(readr))
suppressPackageStartupMessages(require(readxl))
suppressPackageStartupMessages(require(sqltypes))
suppressPackageStartupMessages(require(stringr))
options(scipen=999)


usage <- 'scrub [options] file\n
Clean-up .csv or .xls file and output result as .tsv to STDOUT'
parser <- OptionParser(usage=usage)
parser <- add_option(parser, c("-f", "--schema-file"),default='',
                     help="Path to the .metadata schema associated with file")
parser <- add_option(parser, c("-n", "--na-values"),default='',
                     help="Specify values considered to be NA (use a semicolon to seperate multiple values)")
parser <- add_option(parser, c("-q", "--quote"),default='"',
                     help="Specify the character used to quote strings [default: double-quotes]")
parser <- add_option(parser, c("-K", "--skip-lines"),default=0,type="integer",
                     help="Specify the number of initial lines to skip before the header row")
parser <- add_option(parser, c("-P", "--keep-duplicates"),action="store_true",default=FALSE,
                     help="Do not remove duplicate lines from the input file [default: %default]")
parser <- add_option(parser, c("-b", "--escape-backslash"),action="store_true",default=FALSE,
                     help="Does the file use backslashes to escape special characters? [default: %default]")
parser <- add_option(parser, c("-s", "--split"),action="store_true",default=FALSE,
                     help="Split up input file to process in parallel (RAM friendlier)")
parsed <- parse_args2(parser, args = commandArgs(trailingOnly=TRUE))

prescrub <- function(file) {
  # Convert input into valid UTF-8 and ignore invalid character sequences
  to_utf8 <- 'uconv --from-callback skip --to-code UTF-8'
  # Remove all carriage return characters (usually used in dos style line endings)
  tr <- 'tr -d "\\r"'
  # Replace control chars (except '\t' and '\n') with single space
  sub_cntrl_chars <- 'perl -pe "s/[\\N{U+00}-\\N{U+08}\\N{U+0B}-\\N{U+1F}\\N{U+7F}]/ /g"'
  glue('{to_utf8} "{file}" | {tr} | {sub_cntrl_chars}')
}
read_delim_file <- function(file, options) {
  col_types <- c()
  loc <- list()
  if (options$schema_file != '') {
    schema <- read_delim(options$schema_file,col_names=TRUE,col_types=cols(),delim='|')
    col_names <- c()
    data_types <- c()
    file_prefix <- file %>% basename %>% str_match("([^\\.]+)(\\..+)") %>% nth(2)
    for (idx in 1:(nrow(schema))) {
  numeric_format_match <- str_match(options$numeric_format, "8([:punct:])?999([:punct:])?9?9?")
      numeric_format_match <- str_match(schema[idx,]$data_type, "8([:punct:])?999([:punct:])?9?9?")
      if (!is.na(numeric_format_match[1])) {
         loc$grouping_mark <- ifelse(is.na(numeric_format_match[2]), "", numeric_format_match[2])
         loc$decimal_mark <- ifelse(is.na(numeric_format_match[3]), "", numeric_format_match[3])
      }
      if (file_prefix == schema[idx,]$table_name) {
        col_names <- c(col_names, schema[idx,]$cleaned_name)
        data_types <- c(data_types, list(as.cols(schema[idx,]$data_type)))
      }
    }
    col_types <- setNames(data_types,col_names)
    write(glue('Using schema from file `{options$schema_file}`'), stderr())
    locale <- do.call(readr::locale, loc)
    return(read_delim(file=pipe(prescrub(file)),delim=options$delimiter,col_names=col_names,guess_max=1e5,
             escape_backslash=options$escape_backslash,escape_double=FALSE,trim_ws=TRUE,
             na=options$na_values,skip_empty_rows=TRUE,skip=options$skip_lines+1,
             quote=options$quote,col_types=as.col_spec(col_types),locale=locale))
  }
  locale <- do.call(readr::locale, loc)
  read_delim(file=pipe(prescrub(file)),delim=options$delimiter,col_names=TRUE,guess_max=1e5,
             escape_backslash=options$escape_backslash,escape_double=FALSE,trim_ws=TRUE,
             na=options$na_values,skip_empty_rows=TRUE,skip=options$skip_lines,
             quote=options$quote,col_types=as.col_spec(col_types),locale=locale)
}
split_file <- function(file) {
  orig_dir <- getwd()
  dir_name <- dirname(file)
  header <- readLines(file,n=1)
  setwd(dir_name)
  # Split up input file in such a way that the component parts are never
  # larger than 450MB on a system with 64GB RAM for example
  component_parts_ratio <- 0.007
  mem_max <- str_match(system2("grep", c("MemTotal", "/proc/meminfo"), stdout=TRUE), "(\\d+)\\s+kB")[[2]] %>% as.integer * 1024
  file_part_max_size <- mem_max * component_parts_ratio
  file_size <- file.info(basename(file))$size
  number_of_file_chunks <- ceiling(file_size / file_part_max_size)
  file_prefix <- file %>% basename %>% str_match("([^\\.]+)(\\..+)") %>% nth(2)
  file_suffix <- file %>% basename %>% str_match("([^\\.]+)(\\..+)") %>% nth(3)
  system2("split", c("--numeric-suffixes",
                     "--suffix-length", 6,
                     "--number", number_of_file_chunks,
                     "--additional-suffix", shQuote(file_suffix),
                     file %>% basename %>% shQuote, shQuote(file_prefix)))
  setwd(orig_dir)
  split_files <- Sys.glob(file.path(dirname(file), glue("{file_prefix}??????{file_suffix}")))
  system2("sed", c("--in-place", glue('"1i {header}"'), split_files))
  split_files
}
read_excel_file <- function(file, options) {
  col_types <- c()
  if (options$schema_file != '') {
    schema <- read_csv(options$schema_file,col_names=TRUE,col_types=cols())
    col_names <- c()
    data_types <- c()
    for (idx in 1:(nrow(schema)-1)) {
      col_names <- c(col_names, schema[idx,]$column_name)
      data_types <- c(data_types, list(as.cols(schema[idx,]$data_type)))
    }
    col_types <- setNames(data_types,col_names)
    write(glue('With schema from file `{options$schema_file}`'), stderr())
    sink(stderr());print(as.col_spec(col_types));sink();
  }
  read_excel(file, na=options$na_values, col_names=TRUE, trim_ws=TRUE, guess_max=1e5,
             skip=options$skip_lines, col_types=as.col_spec(col_types))
}
scrub_part <- function(path_to_file, options) {
   df <- read_delim_file(path_to_file, options)
   df <- sanitize_dataframe(df, options$keep_duplicates)
   file_prefix <- str_extract(basename(path_to_file), '[^\\.]+')
   output_path_to_filename <- file.path(dirname(path_to_file), glue("{file_prefix}_scrubbed.tsv"))
   write_tsv(df, output_path_to_filename, na='');
}
scrub <- function(file, options) {
   if (is_excel_file(file)) {
      df <- read_excel(file, na=options$na_values, col_names=TRUE,
                     trim_ws=TRUE, guess_max=1e5, skip=options$skip_lines)
      df <- sanitize_dataframe(df, options$keep_duplicates)
      return(write_tsv(df,file('/dev/stdout',raw=T),na=''))
   }
   options$delimiter <- ifelse(options$skip_lines > 0,
                               file %>% readLines(n=1+options$skip_lines) %>% tail(n=1) %>% get_delimiter,
                               file %>% readLines(n=1) %>% get_delimiter)
   if (options$split) {
      file_parts <- split_file(file)
      if(length(file_parts) > 1) {
        registerDoParallel(cores=ceiling(detectCores()/4))
        file_prefix <- file %>% basename %>% str_match("([^\\.]+)(\\..+)") %>% nth(2)
        foreach(i=1:length(file_parts)) %dopar% scrub_part(file_parts[i],options)
        return(system2('tsv-append', c("--header", file.path(dirname(file),glue("{shQuote(file_prefix)}*_scrubbed.tsv")))))
      } else {
         sink(stderr());print(glue("Warning: not splitting {file} since it's too small"));sink();
      }
   }
   df <- read_delim_file(file, options)
   df <- sanitize_dataframe(df, options$keep_duplicates)
   write_tsv(df,file('/dev/stdout',raw=T),na='')
}
sanitize_dataframe <- function(df, keep_duplicates) {
   df %<>%
      # Remove trailing backslashes to play nicely with csv parsers.
      # Four backslashes in regex patterns translates to one '\', see 
      # https://github.com/rstudio/cheatsheets/blob/master/strings.pdf
      mutate_if(is.character, ~ str_remove(., '(\\\\+)$')) %>%
      # Whitespace all control characters to play nicely with csv parsers
      mutate_if(is.character, ~ str_replace(., '[[:cntrl:]]', fixed(' '))) %>%
      # Remove dirty, misbehaving rows
      {
         if (length(problems(df)$row) > 0)
            slice(.data=., -(problems(df)$row))
         else .
      }
    # Remove duplicates by default
    ifelse(keep_duplicates, df, df %<>% distinct)
    df
}
is_excel_file <- function(file) {
  mime_type <- system2("file", c("--mime-type", shQuote(file)), stdout=TRUE)
  re <- str_c(
    "application/.*ms-excel.*|",
    "application/.*spreadsheet.*|",
    "application/.*zip.*"
  )
  str_detect(mime_type, re)
}
get_delimiter <- function(head) {
  # Return the first occurence of comma, semicolon, pipe or tab
  header <- strsplit(head, split='')[[1]]
  delim_idx <- grep('[,;\\|\t]', header)[1]
  header[delim_idx]
}

write(glue('\nScrubbing {parsed$args[1]}...'), stderr())
parsed$options$na_values <- str_split(parsed$options$na_values, ';')[[1]]
scrub(parsed$args[1], parsed$options)
