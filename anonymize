#!/usr/bin/env node

const _ = require('lodash')
const crypto = require('crypto')
const csv = require('csv')
const faker = require('faker')
const fs = require('fs')
const neodoc = require('neodoc')
const args = neodoc.run(`
Usage:
  anonymize [-h] [--key=<KEY>] [--delimiter=<DELIM>] [--shuffle] [--plan=<FILE>] -

Options:
  -p --plan       Schema file specifying which columns to anonymize and how
  -d --delimiter <delim>  Delimiter to use for parsing STDIN [default: '\t']
  -s --shuffle	  Shuffle (randomize) the order of outputted columns
  -h --help       Show this screen
  -k --key <key>  Key to use when deanonymizing the results [default: /dev/urandom]
  --version       Show version
`, { optionsFirst: true, smartOptions: true, version: "0.1.0" })

const parsePlan = (file) => {
  const data = fs.readFileSync(file, 'utf8')
  // The plan file is three column wide .csv file whose first column is the original
  // column name. The second column is the new column name that should be used in
  // the output file. The last column specifies the faker function to use to 
  // anonymize the values in the columns of the input file
  return _.map(_.initial(data.split('\n')), (row) => {
	  const inputColumnName = row.split(',')[0]
	  const outputColumnName = row.split(',')[1]
	  const fakerFunction = row.split(',')[2]
	  const anonymizeIf = row.split(',')[3]
	  return [inputColumnName, outputColumnName, fakerFunction, anonymizeIf]
  })
}
const deanonymizingKey = args['--key'] || crypto.randomBytes(32)
const delimiter = args['--delimiter'] || '\t'
const anonymizationPlan = parsePlan(args['--plan'])
const fakerSeedNumber = (key, value) => {
  const hmacUsingDeanonymizingKeyAndRecordValue = crypto
        .createHmac('SHA256', key)
        .update(value)
        .digest()
        .toString('hex')
  // The likelyhood of collision with hash size of 64 bits
  // is negligible when we are hashing less than 5e6 cases
  const hashTrimmed = hmacUsingDeanonymizingKeyAndRecordValue
        .substring(0,16)
  return Number(`0x${hashTrimmed}`)
}

// Constrains the columns to be included in the output .csv file
// based on the values in the anonymization plan file
const columnIndicesToIncludeInOutput = (plan) => {
	// Always retrieve the tail on the unzip anonymization plan file
	// since the first line should be the header line
	const newColumnNamesToOutput = _.tail(_.unzip(plan)[1])
	let csvRecordIndicesToOutput = []
	for (let i=0; i < newColumnNamesToOutput.length; i++) {
		if (!_.isEmpty(newColumnNamesToOutput[i])) {
			csvRecordIndicesToOutput.push(i)
		}
	}
	return csvRecordIndicesToOutput
}
// Rewrite the .csv header based on the new column names provided
// in the anonymization plan file
const headerLineWriter = (plan, recordIndicesToOutput) => {
	const secondColumn = _.tail(_.unzip(plan)[1])
	let header = []
	for (let i of recordIndicesToOutput) {
	  header.push(secondColumn[i])
	}
	process.stdout.write(header.join('\t') + '\n')
}

let recordIndicesToOutput
if (args['--shuffle']) {
  recordIndicesToOutput = _.shuffle(columnIndicesToIncludeInOutput(anonymizationPlan))
} else {
  recordIndicesToOutput = columnIndicesToIncludeInOutput(anonymizationPlan)
}
const recordsToAnonymize = _.tail(_.unzip(anonymizationPlan)[2])
const anonymizeIfConditions = _.tail(_.unzip(anonymizationPlan)[3])

const reader = fs.createReadStream('/dev/stdin')
const parser = csv.parse({delimiter: delimiter, skip_lines_with_error: true, from_line: 2})
const transformer = csv.transform(
    (record) => {
    let anonymized = []
    for (let i of recordIndicesToOutput) {
      if (!_.isEmpty(recordsToAnonymize[i])
	      && !_.isEmpty(record[i])
	      && eval(anonymizeIfConditions[i])
      ) {
        faker.seed(fakerSeedNumber(deanonymizingKey, record[i]))
        anonymized.push(faker.fake(`{{${recordsToAnonymize[i]}}}`))
      } else {
        anonymized.push(record[i])
      }
    }
    return anonymized
  }
)
const stringifier = csv.stringify({delimiter: '\t'})

headerLineWriter(anonymizationPlan, recordIndicesToOutput)
reader
  .pipe(parser)
  .pipe(transformer)
  .pipe(stringifier)
  .pipe(process.stdout)
